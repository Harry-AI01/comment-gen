<!DOCTYPE html>
<html lang="en">
  <head>
    <meta charset="UTF-8" />
    <title>Automatic Code Commenting</title>
    <link rel="stylesheet" href="../static/style.css" />
    <script src="../static/script.js"></script>
  </head>
  <body>
    <!-- partial:index.partial.html -->
    <div id="window-wrapper">
      <br>
      <h1 class="typewriter" style="color: #DAC17C" id="main-heading">Add a #Comment to your Python Code.</h1><br>
      <div class="container2">
        <br><br>
        <div id="content-box">
          <textarea
            wrap="soft"
            spellcheck="false"
            id="textarea-input"
          ></textarea>
          <pre id="highlight-area"></pre>
          <button class="button" onclick="get_content({{value}})" id="sendBtn">Submit</button>
        </div>
        <div>
          <h4 class="h4" id="explanation">
            Why is Automatic Code Commenting needed?
            <br>
            <br><br>
            Adding comment lines to a code block not only helps the reader understand the code in the current and referenced methods, but it also helps to determine whether the code is still needed and how to test it. 
            <br><br>

            It is possible that a programmer may forget to add explaining comments for a complex program, or may have added incorrect or inadequate comment lines. A Machine Learning model that can take a block of code and generate comments explaining it would be beneficial for every industry that uses Software applications. It would also be helpful for new programmers who do not understand the best practices for code comments.
            <br><br>
            It's important to keep in mind that comments should be used wisely, as excessive commenting can make the code more difficult to read and can lead to information overload. A good rule of thumb is to comment only when necessary, and to keep comments concise and relevant to the code.<br><br>
             
          </h4>
        </div>
      </div>
    <h1 style="color: #cfdae4;"><br><br><br><br>Approach:</h1>
            <h4 class="h4"><br>
            An attention-based pre-trained transformer model (like BERT) is tuned with a sequence-to-sequence dataset, with code-comment pairs for Python programming language.</h4>
            <div class="container3">
              <img src="../static/gif2.gif"/>___
              <h4 class="h4">Transformer allows direct connections between data units, offering the promise of better capturing long-term dependency. However, in language modeling, Transformers are currently implemented with a fixed-length context, i.e. a long text sequence is truncated into fixed-length segments of a few hundred characters, and each segment is processed separately.<br><br>
              An encoder reading the input sentence and generating a representation of it. A decoder then generates the output sentence word by word while consulting the representation generated by the encoder.<br><br> The Transformer starts by generating initial representations, or embeddings, for each word. These are represented by the unfilled circles. Then, using self-attention, it aggregates information from all of the other words, generating a new representation per word informed by the entire context, represented by the filled balls. This step is then repeated multiple times in parallel for all words, successively generating new representations.</h4>
            </div><p>Source https://ai.googleblog.com/2017/08/transformer-novel-neural-network.html</p>
            <h4 class="h4"><br><br>
              Codet5 is a pretrained transformer based architecture for code understanding and generation. 
              Just like a large language model, it has been trained to model programming languages. The pretrained model is available on huggingface which has been fine tuned on the following dataset which contains Python code and docstring pairs.
              <br><br>
              Dataset:
              <br><br>
              Following is the link to the publicly available dataset.https://huggingface.co/datasets/code_search_net

               <br><br><br><br>As Stack Overflow co-founder Jeff Atwood has written, "Code Tells You How, Comment Tells You Why". This AMP with a successful implementation would be useful for almost all industries around the world, and as Google DeepMind's AlphaCode can generate code blocks for simple programs, therefore, it is also possible for an ML model to be able to understand a piece of code and describe it precisely.
            </h4>  <br><br><br><br>
    </div>    
  </body>
</html>
